# 카프카 리플리케이션 
  
고가용성 분산 스트리밍 플랫폼인 카프카는 무수히 많은 데이터 파이프라인의 정중앙에 위치하는 **메인 허브 역할을 한다.**        

![9961CF3C5C0FBA462C](https://user-images.githubusercontent.com/50267433/150273392-d8e9d94b-2ed8-498f-a458-d348e65f1e98.png)
  
중앙에서 메인 허브 역할을 하는 카프카 클러스터가 어떠한 문제로 인해 정상적으로 동작하지 못한다면         
카프카의 연결된 전체 데이터 파이프라인에 영향을 미치게되므로 이는 매우 심각한 문제가 아닐 수 없다.     
     
따라서 카프카는 초기 설계 단계에서부터 장애가 발생하더라도   
중앙 데이터 허브로서 언정적인 서비스가 운영될 수 있도록 설계가 되어있다.      
  
대표적인 기술 중 하나로 안정성을 확보하기 위해 카프카 내부에서는 리플리케이션이 기능을 지원한다.     

# 리플리케이션 동작 개요 

카프카는 **브로커의 장애에도 불구하고 연속적으로 안정적인 서비스를 제공함으로써 데이터 유실을 방지하여 유연성을 제공한다.**          
카프카의 리플리케이션 동작을 위해 토픽 생성시 **필숫값** 으로, `replication factor` 옵션을 설정하도록 되어있다.      

![img](https://user-images.githubusercontent.com/50267433/191037285-45d985a6-606a-456c-8bf8-bfec95dea3c5.png)

partition 이라는 개념에 대해서 설명하지 않았지만, 
위 프로세스를 간단히 정리하면 아래와 같다.  

1. 특정 토픽에 대해서, parition 을 지정하여 해당 갯수만큼 병렬 처리 작업을 지원한다.  
2. 각 파티션에 대한 리플리케이션(복제)를 만든다.   
3. 그리고 각 파티션마다 리더를 선출해서 해당 리더를 통해서 데이터 쓰기 작업을 진행하면, 리플리케이션 파티션들은 동기화가 된다. 
  
  
## 간단 실습 

설치한 브로커 서버 중 한대로 접근을 해서 리플리케이션 토픽을 하나 생성해보려 한다.(peter-kafka01)   

* 토픽 이름 : peter-test01
* 파티션 수 : 1
* 리플리케이션 팩터 수 : 3

```console
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 \
--create \
--topic peter-test01 \
--partitions 1 \
--replication-factor 3

Created topic peter-test01
```
위와 같이 명령어 실행 후, 생성된 토픽의 정보를 알기 위해서 `describe` 명령어를 사용할 수 있다.   

```console
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 \
--topic peter-test01 \
--describe

Topic: peter-test01 PartitionCount: 1 ReplicationFactor: 3 Configs: segment.bytes=1073741824 
Topic: peter-test01 Partition: 0 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3
```
* 1줄 : 
    * 토픽의 파티션 수인1과 리플리케이션 펙터(토픽) 수인 3이 표시되어있다.      
* 2줄 : 
    * 파티션0에 대한 내용이다.   
    * 파티션0의 리더는 브로커1이다.(리플리케이션중 1번)  
    * 리플리케이션들은 현재 3개가 있음을 나타낸다.(현재 동기화하고 있는 리플리케이션들은 브로커 1,2,3이라는 의미)      
    * 여기서 중요한 사실은 실제로 리플리케이션되는 것은 토픽이 아니라 토픽을 구성하는 파티션들이다.  

```console
/usr/local/kafka/bin/kafka-console-producer.sh --boot-server peter-kafka01.foo.bar:9092 \
--topic peter-test

> test message1
```  
`test message1`메시지를 `peter-test01` 이라는 토픽으로 전송했다.        
이후, 세그먼트 파일에 저장되어있는지 살펴보자     
    
```console
/usr/local/kafka/bin/kafka-dump-log.sh \  
--print-data-log--files /data/kafka-logs/peter-test01-0/00000000000000000000.log
```
```console
Dumping /data/kafka-logs/peter-test01-0/00000000000000000000.log  
Starting offset: 0
baseOffset: 0 lastOffset: 0 count: 1 baseSequence: -1 lastSequence: -1 produerId: -1 
producerEpch: -1 partitionLeaderEpoch: 0 isTransactional: false isControl: false
position: 0 CreateTime: 161008070323 size 81 magic: 2 compresscodec: NONE   
crc: 3417270022 isvalid: true
| offset: 0 CreateTime: 161008070323 ketysize: -1 valuesize: 13 sequence: -1   
headerKeys[] payload: test message1
``` 
* 시작 오픗세은 0임을 알 수 있다.       
* 메시지 카운트는 1임을 알 수 있다.      
* 프로듀서를 통해 보낸 메시지는 test message1 임을 알 수 있다.   

현재 서버는 peter-kafka01 이지만, 카프카 클러스터를 이루는 다른 브로커들에서도 dump 명령어를 실행하면 결과는 같다.   
즉, 콘솔 프로듀서로 보낸 메시지 하나를 총 3대의 브로커들이 모두 갖고 있는 것이다.(덤프 명령어로 접근 가능)     
        
이렇게 카프카는 `replication factor` 옵션을 이용해 관리자가 지정한 수만큼의 리플리케이션을 가질수 있다.      
**N개의 리플리케이션의 경우 `N-1` 까지의 브로커 장애가 발생해도 메시지 손실없이 안정적으로 메시지를 주고받을 수 있다.**         
    
예시 토픽인, `peter-test01`을 기준으로 설명하자면, 총 3개의 리플리케이션들의 요청을 안전하게 처리할 수 있다.     
  
# 리더와 팔로워   

```console
/usr/local/kafka/bin/kafka-topics.sh --bootstrap-server peter-kafka01.foo.bar:9092 \
--topic peter-test01 \
--describe

Topic: peter-test01 PartitionCount: 1 ReplicationFactor: 3 Configs: segment.bytes=1073741824 
Topic: peter-test01 Partition: 0 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3
```
 
토픽 상세보기 명령어를 실행해보면, 출력 내용 중 파티션의 리더라는 부분이 있다.        
**모두 동일한 리플리케이션이라 하더라도 리더만의 역할이 따로 있기 때문에 카프카에서는 리더를 특별히 강조한다.**    
카프카는 내부적으로 동일한 리플리케이션들을 **리더**와 **팔로워**로 구분하고, 각자 역할을 분담시킨다.       

[#](#) 

* **리더 :** 
    * 리플리케이션 중 하나가 선정되며, **모든 읽기와 쓰기는 리더를 통해서만 가능하다.**             
    * 프로듀서는 모든 리플리케이션에 메시지를 보내는 것이 아니라 리더에게만 메시지를 전송한다.       
    * 컨슈머도 오직 리더로부터 메시지를 가져온다.   
* **팔로우 :**
    * 팔로워들 역시 리더에 문제가 발생하거나 이슈가 있을 경우를 대비해 언제든지 새로운 리더가 될 준비를 한다.    
    * 지속적으로 파티션의 리더가 새로운 메시지를 받았는지 확인하고, 새로운 메시지가 있다면 해당 메시지를 리더로부터 복제한다.   
   
# 복제 유지와 커밋   
  
리더와 팔로워는 **`ISR`이라는 논리적 그룹으로 묶여있다.**          
**ISR 그룹에 안에 속한 팔로워들만이 새로운 리더의 자격을 가질 수 있기 때문이다.**           
다시 말해, ISR 그룹에 속하지 못한 팔로워는 새로운 리더의 자격을 가질 수 없다.          
    
**ISR 그룹내의 리더와 팔로워**  
* 리더 : ISR 내 모든 팔로워가 메시지를 받을 때까지 기다린다(성능상 이슈 포인트)   
* 팔로워 : ISR 내 리더와의 데이터 일치를 유지하기 위해 지속적으로 리더의 데이터를 따른다.     

## ISR 그룹핑 이유 

팔로워가 네트워크 오류, 브로커 장애 등 여러 이유로 리더로부터 리플리케이션하지 못하는 경우도 발생할 수 있다.           
팔로워는 이미 리더와의 데이터가 불일치한 상태에 놓이게 되고, 만약 새로운 리더로 임명된다면?            
데이터의 정함섭이나 메시지 손실등의 문제가 발생할 수 있다.         
             
따라서, 파티션의 리더는 팔로워들이 뒤쳐지지 않고 리플리케이션 동작을 잘하고 있는지를 감시해야한다.               
리더에 뒤처지지 않는 팔로워들만이 ISR 그룹에 속하게 되고, 장애가 발생할 경우 리더 자격을 얻을 수 있던 것이다.         

## 동작 판단 기준 
**리더와 팔로워 중 리프리케이션 동작을 잘하고 있는지 여부 등은 누가 어떤 기준으로 판단할까? 🤔**       
  
* **리더**는 읽고 쓰는 동작은 물론, 팔로워가 리플리케이션 동작을 잘 수행하고 있는지도 판단한다.    
        
만약 팔로워가 특정 주기의 시간만큼 복제 요청을 하지 않는다면        
리더는 해당 팔로워가 리플리케이션 동작에 문제가 발생했다고 판단해 ISR 그룹내에서 추방한다.        
즉, **해당 팔로워는 새로운 리더가 될 자격을 박탈당하게 되는 것이다.**      
    
카프카 클러스터 운영중 특정 토픽의 상태가 의심되거나 문제가 있다고 판단되며     
토픽 상세보기 명령어를 통해 현재 ISR 상태를 점검해봄으로써,         
현재 토픽의 상태가 양호한지 불량한지 등을 육안으로 확인할 수 있다.   

ISR 내에서 모든 팔로워의 복제가 완료되면, **리더는 내부적으로 커밋되었다는 표시를 하게 됩니다.**      
마지막 커밋 오프셋 위치는 **하이워터마크**라고 부른다.         
즉, 커밋되었다는 것은 `replication factor` 수의 모든 리플리케이션이 전부 메시지를 저장했음을 의미한다.     
그리고 이렇게 커밋된 메시지만 컨슈머가 읽어갈 수 있다.           
카프카에서 커밋되지 않은 메시지를 컨슈머가 읽을 수 없게 하는 이유는 바로 메시지의 일관성을 유지하기 위해서다.      

[#](#)  
   
`peter-test01` 토픽을 표현한 그림으로,         
해당 토픽은 1개의 파티션과 `3개의 replication factor`로 설정됐다.         
리플리케이션 동작을 설명하기 위해 0번 파티션의 리더와 팔로워를 표시했다. 

프로듀서가 첫번째 test message1이라는 메시지를 peter-test01 토픽으로 보냈고      
모든 팔로워가 리플리케이션 동작을 토앻 모두 저장했으며, 커밌까지 완료된 상태이다.(팔로우는 누가 정해줄까)  
   
이어서 프로듀서가 두번째 test message2 이라는 메시지를 전송했는데,      
이 메시지는 리더만 저장한 상태이고 팔로워들은 아직 해당 메시지에 대해 리플리케이션 동작을 하기 전 상태이다.  

여기서 **커밋 되기 전 메시지를 컨슈머가 읽을 수 있다고 가정하면 어떤 일이 벌어질까?**      

[#](#)    
[#](#)  

위 그림은 각기 다른 컨슈머가 메시지를 컨슘하는 동안 파티션의 리더 선출이 발생한 경우를 나타냈다.     
 
1. 컨슈머 A는 peter-test01 토픽을 컨슘한다.     
2. 컨슈머 A는 peter-test01 토픽의 파티션 리더로부터 메시지를 읽어간다.     
   읽어간 메시지는 test messgae1, 2이다.(단, 리플랙션 동작 전이다.)      
3. peter-test01 토픽의 파티션 리더가 있는 브로커에 문제가 발생해 팔로워 중 하나가 새로운 리더가된다.   
4. 리플리케이션이 반영되기 전에 리더가 바뀌었으므로, 새로운 리더는 test message1 메시지만 가지고 있다.  
5. 새로운 컨슈머 B가 peter-test01 토픽을 컨슘한다.  
6. 새로운 리더로부터 메시지를 읽어가고, 읽어간 메시지는 오직 test messgae1 이다.   

결과적으로 A/B 컨슈머는 각기 다른 메시지를 가지고 있다.   
**카프카는 이러한 문제를 해결하기 위해 커밋된 메시지만 컨슈머가 읽어갈 수 있도록 구현되어 있다.**     

위와 같은 과정을 미루어보아 커밋의 위치가 매우 중요하다는 것을 알 수 있다.  
그렇다면, 커밋의 위치를 어떻게 알 수 있을까?  
   
모든 브로커는 재시작될 때, 커밋된 메시지를 유지하기 위해,       
로컬 디스크의 replication-offset-checkpoint 라는 파일에 마지막 커밋 오프셋 위치를 저장한다.      

```shell
cat /data/kafka-logs/replication-offset-checkpoint
```
* 브로커 설정 파일에서 설정한 로그 디렉토리의 경로에 있다.  
* 브로커 설정 파일의 로그 디렉토리는 /data/kafka-logs 가 디폴트 값이다.   

```
peter-test 0 1
```
* 토픽 이름 : peter-test
* 파티션 번호 : 0
* 커밋된 오프셋 번호 : 1
   
프로듀서로 새 메시지를 보내면 커밋이 증가하는지 확인하자. 
  
```shell
/usr/local/kafka/bin/kafka-console-producer.sh --bootstrap-server peter-kafka01,foo,bar:9092 --topic peter-test01
> test message2
```
```shell
cat /data/kafka-logs/replication-offset-checkpoint
> peter-test 0 2
``` 
위 같은 결과는 파티션 리더뿐 아니라, 다른 파티션 팔로우(토픽) 에도 동일하다.     
만약, 특정 토픽 또는 파티션에 복제가 되지 않는 문제가 발생하면      
`replication-offset-checkpoint`와 대조하여 문제가 있는지 파악하자    

## 리더와 팔로워의 단계별 리플리케이션 동작 
 
카프카로 향하는 수많은 메시지의 읽고 쓰기 처리를 하는 리더는 매우 바쁘게 동작한다.           
여기에 리플리케이션을 위한 팔로워들과의 통신도 많아지면 리더의 성능은 저하될 수 밖에 없다.      
따라서 카프카는 리더와 팔로워간의 리플리케이션 동작을 처리할 때 최소화할 수 있도록 설계함으로써 리더의 부하를 줄일 수 있다.  
  
그럼, 리더와 팔로워간의 리플리케이션은 어떻게 동작하는지 알아보자  

(#)[#]    

위 그릠은 peter-test01 토픽이 3개의 리플리케이션 팩터를 갖고 있음을 알 수 있다.(총 3개의 토픽)     
또한, 현재는 리더만이 0번 오프셋에 message1이라는 메시지를 갖고 있는 상태이다.(복제 되기전)   
프로듀서가 리더에게 message1 이라는 메시지를 전송하고 아직 복제되기 전인 상황이라 보면 된다.    
    
[#](#)   

위 그림은 팔로워들은 리더에게 `0번 오프셋 메시지 가져오기` 요청을 보낸 후         
새로운 메시지 message1 이 있다는 것을 인지하고 message1 메시지를 리플리케이션하는 과정이다.      

현 상태에서 리더는 모든 파로워가 0번 오프셋 메시지를 리플리케이션하기 위한 요청을 보냈다는 사실을 알고 있다.      
하지만, 리더는 팔로워들이 0번 오프셋에 대한 리플리케이션 동작을 성공했는지 실패했는지 여부를 알지는 못한다.        
   
전통적인 메시징 큐 시스템인 rabbiMQ의 트랜잭션 모드에서는     
모든 미러(팔로워)가 메시지를 받았는지에 대한 ACK를 리더에게 리턴하므로, 리더는 미러들이 메시지를 받았는지 알 수 있었다.     
 
**하지만, 카프카의 경우에는 리더와 팔로워 사이에서 ACK를 주고 받는 통신이 없다.**       
오히려 카프카에서는 이 같은 과정을 제거함으로써 리플리케이션 동작의 성능을 더욱 높였다.   
그럼 어떻게 안정적으로 리플리케이션을 할 수 있는 것일까?    
   
[#](#)  

1. 리더는 1번 오프셋의 위치에 2번째 새로운 메시지인 messge2를 프로듀서로부터 받은 뒤 저장한다.   
2. 0번 오프셋에 대한 리플리케이션 동작을 마친 팔로워들은 리더에게 1번 오프셋에 대한 리플리케이션을 요청한다.  
3. 팔로워들로부터 1번 오프셋에 대한 리플리케이션 요청을 받은 리더는 0번 오프셋이 성공했음을 인지하고,   
   0에 대한 커밋 표시를 하고 하이워터마크를 증가시킨다.   
  
팔로워들이 0번에 대한 리플리케이션을 성공하지 못했다면            
팔로워들은 1번이 아닌, 성공하지 못한 0번에 대한 리플리케이션 요청을 다시 보낼 것이다.     
     
**따라서 리더는 팔로워들이 보내는 리플리케이션의 요청의 오프셋을 보고,     
팔로워들이 어느 위치의 오프셋까지 리플리케이션을 제공했는지를 인지할 수 있다.**     

팔로워들로부터 1번 오프셋 메시지에 대한 리플리케이션 요청을 받은 리더는     
응답에 0번 오프셋 message1 메시지가 커밋되었다는 내용도 함께 전달한다.        

[#](#)  
 
리플리케이션의 마지막 과정으로서, 리더의 응답을 받은 모든 팔로워는          
0번 오프셋 메시지가 커밋되었다는 사실을 인지하게 되고, 리더와 동일하게 커밋을 표시한다.          
그리고 1번 오프셋 message2를 리플리케이션 한다.        
이렇게 리더와 팔로워간 메시지의 최신 상태를 유지하게 된다.      
  
여기서 중요한 사실 한 가지가 있다.    
여타 메시징 시스템들은 리플리케이션 동작에서 리더와 팔로워가 메시지를 잘 받았는지 확인하는 ACK 통신을 하지만,     
카프카는 ACK 통신 단꼐를 제거했다는 사실이다.     
   
리더와 팔로워 사이에서 한 두번의 ACK 통신은 성능상 별 다른 문제가 없어보이지만     
대량의 메시지를 처리하는 애플리케이션은 이러한 작은 차이도 크게 부각된다.(만개면, 2만 통신 추가됨)        
이렇게 ACK 통신을 제외한 카프카의 리더는 메시지를 주고 받는 기능에 더욱 집중할 수 있다.   

카프카의 또 다른 장점은 리플리케이션 동작에서 ACK 통신을 제외했음에도 불구하고     
팔로워 리더간의 리플리케이션 동작이 매우 빠르면서도 신뢰할 수 있다는 점이다.    
카프카에서 리더와 팔로워들의 리플리케이션 동작 방식은     
리더가 푸시하는 방식이 아니라 팔로워들이 풀 하는 방식으로 동작하는데,    
풀 방식을 채택한 이유도 리플리케이션 동작에서 리더의 부하를 줄여주기 위함이다.    

## 리더에포크와 복구 
  
리더에 포크는 카프카의 파티션들이 복구 동작을 할 때 메시지의 일관성을 유지하기 위한 용도로 이용된다.       
리더에 포크는 컨트롤러에 의해 관리되는 32비트의 숫자로 표현된다.           
해당 리더에포크 정보는 리플리케이션 프로토콜에 의해 전파되고,   
새로운 리더가 변경된 후 변경된 리더에 대한 정보는 팔로워에게 전달된다.     
리더에 포크는 복구 동작 시 하이워터마크를 대체하는 수단으로 활용된다.   
   
그럼 브로커가 복구 동작을 하는데 왜 리더에포크가 필요한지 알아보자   

[#](#)
  
`peter-test01` 토픽을 나타낸 그림에서   
파티션 수는 1, 리플리케이션 팩터수는2, minsync.replicas 는 1이다.         
현재 설명하고자 하는 예제는 리더에 포크가 없다는 가정하에 장애로부터 복구되는 과정을 설명한다.  
  
1. 리더는 프로듀서로부터 message1 메시지를 받았고, 0번 오프셋에 저장, 팔로워는 리더에게 0번 오프셋에 대한 요쳥을 한다.    
2. 요청을 통해 팔로워는 messgae1 메시지를 리더로부터 리플리케이션 한다.     
3. 리더는 하이워터마크를 1로 올린다.       
4. 리더는 프로듀서로부터 다음 메시지인 message2를 받은 뒤 1번 오프셋에 저장한다.      
5. 팔로워는 다음 메시지인 message2에 대해 리더에게 가져오기 요청을 보내고,     
   응답으로 리더의 하이워터마크 변화를 감지하고 자신의 하이워터마크도 1로 올린다.   
6. 팔로워는 1번 오프셋의 message2를 리더로부터 리플리케이션 한다.   
7. 팔로워는 2번 오프셋에 대한 요청을 리더에게 보내고, 요청을 받은 리더는 하이워터마크를 2로 올린다.   
8. 팔로워는 2번 오프셋인 message2 메시지까지 리플리케이션을 완료했지만,    
   아직 리더로부터 하이워터마크를 2로 올리는 내용은 전달받지 못한 상태다.     
9. 예상하지 못한 장애로 팔로워가 다운된다.   
    
즉, 리더가 하이워터마크를 증가시키기전에 팔로워에서 요청이 먼저 들어옴으로써    
하이워터마크에 대한 응답을 받지 못한 것이다.    
  
[#](#) 

위 그림은 **장애가 발생한 팔로워가 종료된 후 장애 처리가 완료된 상태를 나타낸다.**          
장애에서 복구된 팔로워는 카프카 프로세스가 시작되면서 내부적으로 메시지 복구 동작을 하게 된다.       

1. 팔로워는 자신이 갖고 있는 메시지들 중에서 자신의 워터마크보다 높은 메시지들은 신뢰할 수 없는 메시지로 판단하고 삭제한다.    
   따라서 1번 오프셋의 message2는 삭제된다.      
2. 팔로워는 리더에게 1번 오프셋의 새로운 메시지에 대한 가져오기 요청을 한다.  
3. 이순간 리더였던 브로커가 예쌍치 못한 장애로 다운되면서, 해당 파티션에 유일하게 남아있던 팔로워가 새로운 리더로 승격된다.   
  
[#](#)  
  
팔로워가 새로운 리더로 승격된 후의 그림은 위와 같다.      
그림에서 알 수 있듯이 새로운 리더는 message2를 가지고 있지 않는 리더이다.        
리더와 팔로워간의 리플리케이션이 있음에도 불구하고, 리더가 변경되는 과정을 통해 최종적으로 1번 오프셋의 message2 메시지가 손실되었다.    
  
복구 동작시 메시지 일관성을 유지하기 위해 리더에포크를 활용한다고 앞서 말했다.   
리더에 포크를 적용하면 어떤 차이가 있는지 확인하자   

[#](#)  
      
위 그림은 리더와 팔로워의 리플리케이션 동작 이후, 즉 팔로워가 장애로 종료된 후 막 복구된 상태 이후의 과정이다.              
앞선 동작에서는 카프카 프로세스가 시작되면서 복구 동작을 통해 자신의 하이워터마크보다 높은 메시지를 즉시 삭제했다.         
하지만, 리더에포크를 사용하는 경우에는 하이워터마크보다 앞에 있는 메시지를 무조건 삭제하는 것이 아니라 리더에게 리더에 포크 요청을 보낸다.      
   
1. 팔로워는 복구 동작을 하면서 리더에게 리더에포크 요청을 보낸다.      
2. 요청을 받은 리더는 리더에포크의 응답으로 '1번 오프셋의 message2 까지'라고 팔로워에게 보낸다.       
3. 팔로워는 자신의 하이워터마크보다 높은 1번 오프셋의 message2를 삭제하지 않고,     
   리더의 응답을 확인한 후 message2 까지 자신의 하이워터마크를 상향 조정합니다.    

[#](#)   

즉, 리더가 예상치 못한 장애로 다운되면서 팔로워가 새로운 리더로 승격된 후의 상태를 나타낸다.       
리더에포크를 적용하지 않는 경우에는      
팔로워가 message2 메시지를 갖고 있음에도 복구 과정에서 하이워터마크보다 높은 메시지를 삭제했다.     
    
하지만, 리더에포크를 사용하는 경우에는 삭제 동작을 하기에 앞서        
리더에포크 요청과 응답 과정을 통해 팔로워의 하이워터마크를 올릴 수 있었고, 메시지 손실은 발생하지 않았다.(오프셋과 메시지로 검증)   

이제 리더에포크를 적용하지 않았을 때 발생할 수 있는 또다른 예제를 살펴보자.   

[#](#)   

리더만 오프셋1까지 저장했고, 팔로워는 아직 1번 오프셋 메시지에 대해 리플리케이션 동작을 완료하지 못한 상태이다.        
현 시점에서 해당 브로커들의 장애가 발생해 리더와 팔로워 모두 다운되었다고 가정한다.       

[#](#) 

브로커가 모두 종료된 후 팔로워가 있던 브로커 장애에서 복구된 상태다.   
현재 상태에서 복구 동작이 일어나는 과정은 아래와 같다.  
 
1. 팔로워였던 브로커가 장애에서 먼저 복구된다.      
2. peter-test01 토픽의 0번 파티션에 리더가 없으므로 팔로워는 새로운 리더로 승격된다.      
3. 새로운 리더는 프로듀서로부터 다음 메시지 message3를 전달받고 1번 오프셋에 저장한 후, 자신의 하이워터마크를 상향조정한다.  

[#](#)  

다음 과정으로, 구 리더였던 브로커도 장애에서 복구된 상태를 나타낸다.    
이번에는 구 리더였던 브로커의 복구 과정을 알아보자  
  
1. 구 리더였던 브로커가 장애에서 복구된다.      
2. peter-test01 토픽의 0번 파티션에 이미 리더가 있으므로, 복구된 브로커는 팔로워가 됩니다.   
3. 리더와 메시지 정합성 확인을 위해 자신의 하이워터마크를 비교해보니,   
   리더의 하이워터마크와 잂치하므로, 브로커는 자신이 갖고 있던 메시지를 삭제하지 않는다.  
4. 리더는 프로듀서로부터 message4 메시지를 받은 후 오프셋2의 위치에 저장한다.   
5. 팔로워는 오프셋2인 message4를 리플리케이션하기 위해 준비한다.  
 
중간 부분을 보면,  
뉴리더는 1번 오프셋 위치에 message3을 갖고 있고,     
팔로워는 1번 오프셋 위치에 message2를 가지고 있다.     
 
리더와 팔로워 둘다 동일한 하이워터마크를 나타내고 있지만 서로의 메시지는 다르다.      
리더와 팔로워가 메시지의 동일한 오프셋 위치만을 이용해 복구한다면, 서로의 메시지가 불일치하는 경우가 발생한다.    
그럼 리더에포크를 이용하면 이러한 문제도 해결될까?     

[#](#)

팔로워가 먼저 복구되어 뉴리더가 되었고 구 리더였던 브로커가 장애에서 복구된 상태를 나타낸다.       
여기서 가장 중요한 점은 뉴리더가 자신이 팔로워일 때의 하이워터마크와 뉴리더일 때의 하이워터마크임을 알고 있다는 사실이다.      
 
1. 구 리더였던 브로커가 장애에서 복구된다.       
2. peter-test01 토픽의 0번 파티션에 이미 리더가 있고 자신은 팔로워가 된다.       
3. 팔로워는 뉴 리더에게 리더에포크 요청을 보낸다.     
4. 뉴리더는 0번 오프셋까지 유효하다고 응답한다.    
5. 팔로워는 메시지 일관성을 위해 로컬 파일에서 1번 오프셋인 message2를 삭제한다.     
   (팔로워는 쓰기 권한이 없으므로, 리더에게 message2를 추가할 수 없다)     
6. 팔로워는 리더로부터 1번 오프셋인 message3을 리플리케이션하기 위해 준비한다.   

지금까지 리더에포크를 사용하지 않았을 때, 발생할 수 있는 문제점의 사례와        
리더에포크를 사용할 때의 복구 사례를 통해 리더에포크의 역할을 살펴봤다.        
카프카를 구성하는 기능 중 리더에포크는 이처럼 매우 중요한 역할을 한다.       

방금 설명한 장애 복구 사례에서 어떻게 뉴리더가 message1(오프셋0)까지 신뢰할 수 있다고 응답할 수 있는지 궁금할 수 있다.   
리더에포크 요청과 응답에는 리더에포크 번호와 커밋된 오프셋 번호를 이용하는데,      
이제부터 실습을 통해 리더에포크의 변화 과정을 정확하게 이해해자.     

### 실습 










   










   





